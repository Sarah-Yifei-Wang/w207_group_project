{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Shape : (137166, 23)\n",
      "Index(['Unnamed: 0', 'Zip Code', 'Month of Period End', 'Median Sale Price',\n",
      "       'Median Sale Price MoM ', 'Median Sale Price YoY ', 'Homes Sold',\n",
      "       'Homes Sold MoM ', 'Homes Sold YoY ', 'New Listings',\n",
      "       'New Listings MoM ', 'New Listings YoY ', 'Inventory', 'Inventory MoM ',\n",
      "       ' Inventory YoY ', 'Days on Market', 'Days on Market MoM',\n",
      "       'Days on Market YoY', 'Average Sale To List',\n",
      "       'Average Sale To List MoM ', 'Average Sale To List YoY ',\n",
      "       'record_month', 'PSSF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#load dataframe from csv\n",
    "merged_sales = pd.read_csv(\"data/zip/merged_sales_stats.csv\", delimiter='\t')\n",
    "\n",
    "#print dataframe shape\n",
    "shape = merged_sales.shape\n",
    "print('\\nDataFrame Shape :', shape)\n",
    "\n",
    "print(merged_sales.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merged_sales_statistics file has all the statistics as columns and zip codes and dates as the rows. I tried to transpose these but it got weird. So let's get some stuff from the merged_sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1688, 682)\n",
      "Index(['Unnamed: 0', 'Zip Code', 'June 2009 1bd', 'July 2009 1bd',\n",
      "       'August 2009 1bd', 'September 2009 1bd', 'October 2009 1bd',\n",
      "       'November 2009 1bd', 'December 2009 1bd', 'January 2010 1bd',\n",
      "       ...\n",
      "       'December 2019 5bd', 'January 2020 5bd', 'February 2020 5bd',\n",
      "       'March 2020 5bd', 'April 2020 5bd', 'May 2020 5bd', 'June 2020 5bd',\n",
      "       'July 2020 5bd', 'August 2020 5bd', 'September 2020 5bd'],\n",
      "      dtype='object', length=682)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load dataframe from csv\n",
    "merged_bedroom_data = pd.read_csv(\"data/zip/merged_bedrooms.csv\", delimiter='\t')\n",
    "print(merged_bedroom_data.shape)\n",
    "print(merged_bedroom_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 207)\n",
      "0     29.100000\n",
      "1     31.900000\n",
      "2     30.700001\n",
      "3     37.599998\n",
      "4     33.000000\n",
      "5     36.099998\n",
      "6     30.799999\n",
      "7     33.700001\n",
      "8     29.500000\n",
      "9     29.100000\n",
      "10    33.299999\n",
      "11    30.299999\n",
      "12    32.099998\n",
      "13    31.799999\n",
      "14    27.299999\n",
      "15    32.799999\n",
      "16    29.900000\n",
      "17    42.599998\n",
      "18    32.099998\n",
      "19    30.799999\n",
      "20    33.200001\n",
      "21    32.400002\n",
      "22    33.000000\n",
      "23    32.700001\n",
      "24    22.299999\n",
      "25    31.500000\n",
      "26    33.099998\n",
      "27    27.600000\n",
      "28    33.000000\n",
      "29    27.600000\n",
      "30    32.200001\n",
      "31    27.200001\n",
      "32    30.600000\n",
      "33    31.500000\n",
      "34    31.700001\n",
      "35    33.500000\n",
      "36    26.700001\n",
      "37    29.400000\n",
      "38    33.200001\n",
      "39    31.000000\n",
      "40    30.600000\n",
      "Name: SE_A18003_001, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "now for our demographic info, it's from 2019 so not super up to date, but pretty close and there's a lot of it\n",
    "'''\n",
    "demographics = pd.read_csv(\"data/zip/ca_demographics.csv\", delimiter='\t')\n",
    "zip_to_county = pd.read_csv(\"data/zip/zip_to_county.csv\", delimiter='\t')\n",
    "\n",
    "print(demographics.shape) # a lot of blank columns\n",
    "\n",
    "\n",
    "print(demographics[\"SE_A18003_001\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the column names are gibberish, so we'll need to use the [ca_demographics_key.txt](data/zip/ca_demographics_key.txt) to make sense of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1763, 217)\n"
     ]
    }
   ],
   "source": [
    "zipdemo = pd.read_csv(\"data/zip/ca_zip_demograhics.csv\", delimiter='\t')\n",
    "print(zipdemo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot to look at in that dataset, but certainly all the key indicators about the zip should give us at least some picture of what the housing market there might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Condensing Sale Data to Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove month from \"Month of Period End\"\n",
    "only_year_query = \"\"\"SELECT \"Zip Code\" as zip_code, \n",
    "                    SUBSTR(\"Month of Period End\" ,-4) as year,\n",
    "                    \"Median Sale Price\" as med_sale_price,\n",
    "                    \"Homes Sold\" as home_sold,\n",
    "                    \"New Listings\" as new_listings,\n",
    "                    \"Inventory\" as inventory,\n",
    "                    \"Days on Market\" as days_on_market,\n",
    "                    \"Average Sale To List\" as avg_sale_to_list,\n",
    "                    PSSF as ppsf\n",
    "                    FROM merged_sales\"\"\"\n",
    "only_year = ps.sqldf(only_year_query, locals())\n",
    "\n",
    "#group by year\n",
    "cond_year_query = \"\"\"SELECT zip_code, \n",
    "                            year,\n",
    "                            AVG(med_sale_price) as med_sale_price,\n",
    "                            SUM(home_sold) as homes_sold,\n",
    "                            SUM(new_listings) as new_listings,\n",
    "                            AVG(inventory) as inventory,\n",
    "                            AVG(days_on_market) as days_on_market,\n",
    "                            AVG(avg_sale_to_list) as avg_sale_to_list,\n",
    "                            AVG(ppsf) as ppsf\n",
    "                    FROM only_year\n",
    "                    GROUP BY year, zip_code\"\"\"\n",
    "cond_year = ps.sqldf(cond_year_query, locals())\n",
    "\n",
    "#filtering to 2018\n",
    "year_18_query = \"\"\"SELECT *\n",
    "                    FROM cond_year\n",
    "                    WHERE year = '2018' \"\"\"\n",
    "year_18 = ps.sqldf(year_18_query, locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018 Sales and Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>year</th>\n",
       "      <th>med_sale_price</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>new_listings</th>\n",
       "      <th>inventory</th>\n",
       "      <th>days_on_market</th>\n",
       "      <th>avg_sale_to_list</th>\n",
       "      <th>ppsf</th>\n",
       "      <th>Geo_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>SE_A08002B_005</th>\n",
       "      <th>SE_A08002B_006</th>\n",
       "      <th>SE_A10066_001</th>\n",
       "      <th>SE_A10066_002</th>\n",
       "      <th>SE_A10066_003</th>\n",
       "      <th>SE_A10066_004</th>\n",
       "      <th>SE_A10066_005</th>\n",
       "      <th>SE_A10066_006</th>\n",
       "      <th>SE_A10066_007</th>\n",
       "      <th>SE_A10066_008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90001</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.228333e+05</td>\n",
       "      <td>511</td>\n",
       "      <td>678.0</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>100.125000</td>\n",
       "      <td>322.500000</td>\n",
       "      <td>90090001</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>118</td>\n",
       "      <td>13815</td>\n",
       "      <td>1834</td>\n",
       "      <td>2083</td>\n",
       "      <td>2594</td>\n",
       "      <td>2513</td>\n",
       "      <td>2045</td>\n",
       "      <td>1330</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90002</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.825000e+05</td>\n",
       "      <td>964</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>39.916667</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>323.750000</td>\n",
       "      <td>90090002</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>124</td>\n",
       "      <td>12706</td>\n",
       "      <td>2096</td>\n",
       "      <td>2232</td>\n",
       "      <td>2020</td>\n",
       "      <td>2266</td>\n",
       "      <td>1719</td>\n",
       "      <td>895</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90003</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.076667e+05</td>\n",
       "      <td>962</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>45.416667</td>\n",
       "      <td>99.933333</td>\n",
       "      <td>314.166667</td>\n",
       "      <td>90090003</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>129</td>\n",
       "      <td>17127</td>\n",
       "      <td>2594</td>\n",
       "      <td>2479</td>\n",
       "      <td>2966</td>\n",
       "      <td>3345</td>\n",
       "      <td>2757</td>\n",
       "      <td>1476</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90004</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.286500e+06</td>\n",
       "      <td>747</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>99.233333</td>\n",
       "      <td>630.916667</td>\n",
       "      <td>90090004</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>463</td>\n",
       "      <td>21971</td>\n",
       "      <td>6379</td>\n",
       "      <td>6385</td>\n",
       "      <td>3842</td>\n",
       "      <td>2854</td>\n",
       "      <td>1539</td>\n",
       "      <td>721</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90005</td>\n",
       "      <td>2018</td>\n",
       "      <td>7.710000e+05</td>\n",
       "      <td>314</td>\n",
       "      <td>446.0</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>99.225000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>90090005</td>\n",
       "      <td>...</td>\n",
       "      <td>431</td>\n",
       "      <td>380</td>\n",
       "      <td>16442</td>\n",
       "      <td>6298</td>\n",
       "      <td>4939</td>\n",
       "      <td>2183</td>\n",
       "      <td>1794</td>\n",
       "      <td>832</td>\n",
       "      <td>293</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>96146</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.807500e+05</td>\n",
       "      <td>249</td>\n",
       "      <td>368.0</td>\n",
       "      <td>62.666667</td>\n",
       "      <td>163.333333</td>\n",
       "      <td>95.691667</td>\n",
       "      <td>486.333333</td>\n",
       "      <td>96196146</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>454</td>\n",
       "      <td>152</td>\n",
       "      <td>215</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>96148</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.440833e+05</td>\n",
       "      <td>155</td>\n",
       "      <td>156.0</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>96.950000</td>\n",
       "      <td>413.666667</td>\n",
       "      <td>96196148</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>96150</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.536667e+05</td>\n",
       "      <td>2333</td>\n",
       "      <td>3039.0</td>\n",
       "      <td>246.333333</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>97.008333</td>\n",
       "      <td>307.666667</td>\n",
       "      <td>96196150</td>\n",
       "      <td>...</td>\n",
       "      <td>461</td>\n",
       "      <td>24</td>\n",
       "      <td>11536</td>\n",
       "      <td>3645</td>\n",
       "      <td>4315</td>\n",
       "      <td>1666</td>\n",
       "      <td>1221</td>\n",
       "      <td>427</td>\n",
       "      <td>202</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>96155</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.340000e+05</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>91.333333</td>\n",
       "      <td>145.666667</td>\n",
       "      <td>96196155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>96161</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.946667e+05</td>\n",
       "      <td>2534</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>289.500000</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>97.816667</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>96196161</td>\n",
       "      <td>...</td>\n",
       "      <td>233</td>\n",
       "      <td>59</td>\n",
       "      <td>6929</td>\n",
       "      <td>1385</td>\n",
       "      <td>2772</td>\n",
       "      <td>1087</td>\n",
       "      <td>1437</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1337 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zip_code  year  med_sale_price  homes_sold  new_listings   inventory  \\\n",
       "0        90001  2018    4.228333e+05         511         678.0   44.333333   \n",
       "1        90002  2018    3.825000e+05         964        1178.0   74.666667   \n",
       "2        90003  2018    4.076667e+05         962        1222.0   96.000000   \n",
       "3        90004  2018    1.286500e+06         747        1117.0   85.833333   \n",
       "4        90005  2018    7.710000e+05         314         446.0   30.666667   \n",
       "...        ...   ...             ...         ...           ...         ...   \n",
       "1332     96146  2018    5.807500e+05         249         368.0   62.666667   \n",
       "1333     96148  2018    6.440833e+05         155         156.0   14.583333   \n",
       "1334     96150  2018    4.536667e+05        2333        3039.0  246.333333   \n",
       "1335     96155  2018    2.340000e+05           8           NaN         NaN   \n",
       "1336     96161  2018    6.946667e+05        2534        3015.0  289.500000   \n",
       "\n",
       "      days_on_market  avg_sale_to_list        ppsf  Geo_FIPS  ...  \\\n",
       "0          43.166667        100.125000  322.500000  90090001  ...   \n",
       "1          39.916667         99.916667  323.750000  90090002  ...   \n",
       "2          45.416667         99.933333  314.166667  90090003  ...   \n",
       "3          33.833333         99.233333  630.916667  90090004  ...   \n",
       "4          30.250000         99.225000  523.000000  90090005  ...   \n",
       "...              ...               ...         ...       ...  ...   \n",
       "1332      163.333333         95.691667  486.333333  96196146  ...   \n",
       "1333       90.500000         96.950000  413.666667  96196148  ...   \n",
       "1334       43.750000         97.008333  307.666667  96196150  ...   \n",
       "1335      104.000000         91.333333  145.666667  96196155  ...   \n",
       "1336       65.250000         97.816667  367.000000  96196161  ...   \n",
       "\n",
       "     SE_A08002B_005 SE_A08002B_006 SE_A10066_001 SE_A10066_002  SE_A10066_003  \\\n",
       "0               144            118         13815          1834           2083   \n",
       "1                45            124         12706          2096           2232   \n",
       "2               193            129         17127          2594           2479   \n",
       "3               483            463         21971          6379           6385   \n",
       "4               431            380         16442          6298           4939   \n",
       "...             ...            ...           ...           ...            ...   \n",
       "1332              0              9           454           152            215   \n",
       "1333             24              0           210            55             62   \n",
       "1334            461             24         11536          3645           4315   \n",
       "1335              0              0             0             0              0   \n",
       "1336            233             59          6929          1385           2772   \n",
       "\n",
       "      SE_A10066_004 SE_A10066_005  SE_A10066_006 SE_A10066_007 SE_A10066_008  \n",
       "0              2594          2513           2045          1330          1416  \n",
       "1              2020          2266           1719           895          1478  \n",
       "2              2966          3345           2757          1476          1510  \n",
       "3              3842          2854           1539           721           251  \n",
       "4              2183          1794            832           293           103  \n",
       "...             ...           ...            ...           ...           ...  \n",
       "1332             31            24             32             0             0  \n",
       "1333              6            50             26             0            11  \n",
       "1334           1666          1221            427           202            60  \n",
       "1335              0             0              0             0             0  \n",
       "1336           1087          1437            187             0            61  \n",
       "\n",
       "[1337 rows x 226 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zip code = Geo_ZCTA5\n",
    "\n",
    "sales_demo_query = \"\"\"SELECT year_18.*, zipdemo.*\n",
    "                    FROM year_18\n",
    "                    INNER JOIN zipdemo on zip_code = Geo_ZCTA5\n",
    "                    \"\"\"\n",
    "sales_demo = ps.sqldf(sales_demo_query, locals())\n",
    "sales_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DoM_group</th>\n",
       "      <th>COUNT(zip_code)</th>\n",
       "      <th>MAX(days_on_market)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>21.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>268</td>\n",
       "      <td>34.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>267</td>\n",
       "      <td>44.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>59.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>267</td>\n",
       "      <td>2833.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DoM_group  COUNT(zip_code)  MAX(days_on_market)\n",
       "0          1              268            21.416667\n",
       "1          2              268            34.750000\n",
       "2          3              267            44.083333\n",
       "3          4              267            59.416667\n",
       "4          5              267          2833.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create avg_sale_to_list groups (split into 5)\n",
    "ntile_DoM_query = \"\"\"SELECT *, NTILE(5) OVER (\n",
    "                            ORDER BY days_on_market ASC) as DoM_group      \n",
    "                        FROM sales_demo\"\"\"\n",
    "ntile_DoM = ps.sqldf(ntile_DoM_query, locals())\n",
    "\n",
    "\n",
    "#see group maximums\n",
    "minmax_DoM_query = \"\"\"SELECT DoM_group, COUNT(zip_code), MAX(days_on_market)\n",
    "                        FROM ntile_DoM\n",
    "                        GROUP BY DoM_group\"\"\"\n",
    "minmax_DoM = ps.sqldf(minmax_DoM_query, locals())\n",
    "minmax_DoM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Delete non-numeric and unused columns.\n",
    "del_col = ['Geo_FIPS', 'Geo_GEOID', 'Geo_NAME', 'Geo_QName', 'Geo_STUSAB', 'Geo_SUMLEV', \n",
    "           'Geo_GEOCOMP', 'Geo_FILEID', 'Geo_LOGRECNO', 'Geo_US', 'Geo_REGION', 'Geo_DIVISION', \n",
    "          'Geo_STATECE', 'Geo_STATE', 'Geo_COUNTY', 'Geo_COUSUB', 'Geo_PLACE', 'Geo_PLACESE', \n",
    "          'Geo_TRACT', 'Geo_BLKGRP', 'Geo_CONCIT', 'Geo_AIANHH', 'Geo_AIANHHFP', 'Geo_AIHHTLI', \n",
    "          'Geo_AITSCE', 'Geo_AITS', 'Geo_ANRC', 'Geo_CBSA', 'Geo_CSA', 'Geo_METDIV', 'Geo_MACC', \n",
    "          'Geo_MEMI', 'Geo_NECTA', 'Geo_CNECTA', 'Geo_NECTADIV', 'Geo_UA', 'Geo_UACP', 'Geo_CDCURR', \n",
    "          'Geo_SLDU', 'Geo_SLDL', 'Geo_VTD', 'Geo_ZCTA3', 'Geo_SUBMCD', 'Geo_SDELM', 'Geo_SDSEC', \n",
    "          'Geo_SDUNI', 'Geo_UR', 'Geo_PCI', 'Geo_TAZ', 'Geo_UGA', 'Geo_BTTR', 'Geo_BTBG', \n",
    "          'Geo_PUMA5', 'Geo_PUMA1', 'year','Geo_ZCTA5', 'avg_sale_to_list']\n",
    "for i in del_col:\n",
    "    del ntile_DoM[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables to hold test and training data.\n",
    "\n",
    "ntile_10_noDOM = ntile_10_DoM.drop(columns=[\"days_on_market\"])\n",
    "\n",
    "# Shuffle data frame.\n",
    "shuffled = ntile_10_noDOM.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Remove blanks and NaNs\n",
    "shuffled.replace('', np.nan)\n",
    "shuffled = shuffled.dropna(axis=0, how='any')\n",
    "\n",
    "# Split into data and labels.\n",
    "labels = shuffled[\"DoM_10_group\"]\n",
    "del shuffled[\"DoM_10_group\"]\n",
    "zip_codes = shuffled[\"zip_code\"]\n",
    "del shuffled[\"zip_code\"]\n",
    "shuffled = shuffled.apply(lambda x: pd.to_numeric(x))\n",
    "\n",
    "# Create 80% split point.\n",
    "split = int(len(shuffled)*0.8//1)\n",
    "\n",
    "# Store in variables.\n",
    "train_data = shuffled[:split]\n",
    "train_labels = labels[:split]\n",
    "test_data = shuffled[split+1:]\n",
    "test_labels = labels[split+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40577059 0.15731246 0.10018623 0.05253975 0.02949614 0.02241807\n",
      " 0.01805378 0.01790191 0.01596616 0.01481254 0.01208041 0.01000423\n",
      " 0.00899176 0.00823108 0.00796432 0.00675859 0.0058174  0.00556391\n",
      " 0.00517465 0.00500113]\n",
      " percent of variance captured::  0.9100451003750964\n",
      "[152.90020519  95.20271733  75.97519018  55.01888513  41.22402221\n",
      "  35.93907195  32.25164293  32.11570934  30.3296959   29.21343424\n",
      "  26.38205101  24.00819721  22.76093775  21.77690366  21.42111245\n",
      "  19.73312232  18.3076316   17.90431278  17.26666297  16.97469126]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize all of our data if possible\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(train_data)\n",
    "X_test = sc.transform(test_data)\n",
    "\n",
    "#now perform PCA\n",
    "pca = PCA(n_components=20)\n",
    "#pca.fit(X_train)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\" percent of variance captured:: \", np.sum(pca.explained_variance_ratio_))\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our PCA model w/Random Forest and no days on market :  0.3023255813953488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=32, random_state=0)\n",
    "classifier.fit(X_train, train_labels)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predicted_labels = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate number of incorrect values for each model.\n",
    "num_wrong = sum(test_labels != predicted_labels)\n",
    "accuracy = (len(test_labels) - num_wrong) / len(test_labels)\n",
    "print(\"Accuracy of our PCA model w/Random Forest and no days on market : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 1 1 4 2 1 1 1 2 3 4 3 3 3 4 4 4 1 1 1 1 2 1 4 5 4 4 1 4 4 1 4 3 4 2\n",
      " 4 5 1 5 5 3 3 1 1 3 4 1 2 2 4 4 1 1 3 5 2 1 5 2 3 2 1 4 5 2 5 1 3 1 3 3 5\n",
      " 3 3 2 1 1 1 3 3 3 2 3 3]\n",
      "0.9767441860465116\n",
      "Thresh=0.001, n=15, Accuracy: 97.67%\n",
      "Thresh=0.001, n=14, Accuracy: 97.67%\n",
      "Thresh=0.001, n=13, Accuracy: 97.67%\n",
      "Thresh=0.002, n=12, Accuracy: 97.67%\n",
      "Thresh=0.002, n=11, Accuracy: 97.67%\n",
      "Thresh=0.002, n=10, Accuracy: 97.67%\n",
      "Thresh=0.002, n=9, Accuracy: 97.67%\n",
      "Thresh=0.002, n=8, Accuracy: 97.67%\n",
      "Thresh=0.002, n=7, Accuracy: 97.67%\n",
      "Thresh=0.002, n=6, Accuracy: 97.67%\n",
      "Thresh=0.003, n=5, Accuracy: 97.67%\n",
      "Thresh=0.003, n=4, Accuracy: 97.67%\n",
      "Thresh=0.003, n=3, Accuracy: 97.67%\n",
      "Thresh=0.006, n=2, Accuracy: 97.67%\n",
      "Thresh=0.968, n=1, Accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(train_data, train_labels)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(test_data)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate number of incorrect values for each model.\n",
    "num_wrong = sum(test_labels != y_pred)\n",
    "accuracy = (len(test_labels) - num_wrong) / len(test_labels)\n",
    "print(accuracy)\n",
    "\n",
    "# accuracy = accuracy_score(test_data, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# Fit model using each importance as a threshold\n",
    "\n",
    "thresholds = np.sort(model.feature_importances_)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    if(thresh > 0.00001):\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(train_data)\n",
    "        # train model\n",
    "        selection_model = XGBClassifier()\n",
    "        selection_model.fit(select_X_train, train_labels)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(test_data)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        #predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(test_labels, y_pred)\n",
    "        print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create avg_sale_to_list groups (split into 5)\n",
    "ntile_10_DoM_query = \"\"\"SELECT *, NTILE(10) OVER (\n",
    "                            ORDER BY days_on_market ASC) as DoM_10_group      \n",
    "                        FROM sales_demo\"\"\"\n",
    "ntile_10_DoM = ps.sqldf(ntile_10_DoM_query, locals())\n",
    "\n",
    "\n",
    "#see group maximums\n",
    "minmax_10_DoM_query = \"\"\"SELECT DoM_10_group, COUNT(zip_code), MAX(days_on_market)\n",
    "                        FROM ntile_10_DoM\n",
    "                        GROUP BY DoM_10_group\"\"\"\n",
    "minmax_10_DoM = ps.sqldf(minmax_10_DoM_query, locals())\n",
    "\n",
    "#Delete non-numeric and unused columns.\n",
    "del_col = ['Geo_FIPS', 'Geo_GEOID', 'Geo_NAME', 'Geo_QName', 'Geo_STUSAB', 'Geo_SUMLEV', \n",
    "           'Geo_GEOCOMP', 'Geo_FILEID', 'Geo_LOGRECNO', 'Geo_US', 'Geo_REGION', 'Geo_DIVISION', \n",
    "          'Geo_STATECE', 'Geo_STATE', 'Geo_COUNTY', 'Geo_COUSUB', 'Geo_PLACE', 'Geo_PLACESE', \n",
    "          'Geo_TRACT', 'Geo_BLKGRP', 'Geo_CONCIT', 'Geo_AIANHH', 'Geo_AIANHHFP', 'Geo_AIHHTLI', \n",
    "          'Geo_AITSCE', 'Geo_AITS', 'Geo_ANRC', 'Geo_CBSA', 'Geo_CSA', 'Geo_METDIV', 'Geo_MACC', \n",
    "          'Geo_MEMI', 'Geo_NECTA', 'Geo_CNECTA', 'Geo_NECTADIV', 'Geo_UA', 'Geo_UACP', 'Geo_CDCURR', \n",
    "          'Geo_SLDU', 'Geo_SLDL', 'Geo_VTD', 'Geo_ZCTA3', 'Geo_SUBMCD', 'Geo_SDELM', 'Geo_SDSEC', \n",
    "          'Geo_SDUNI', 'Geo_UR', 'Geo_PCI', 'Geo_TAZ', 'Geo_UGA', 'Geo_BTTR', 'Geo_BTBG', \n",
    "          'Geo_PUMA5', 'Geo_PUMA1', 'year','Geo_ZCTA5', 'avg_sale_to_list']\n",
    "for i in del_col:\n",
    "    del ntile_10_DoM[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntile_10_noDOM = ntile_10_DoM.drop(columns=[\"days_on_market\"])\n",
    "ntile_10_noDOM['Availability'] = ntile_10_noDOM.apply(lambda row: row.new_listings / np.maximum(1.0, row.SE_A00002_002), axis = 1)\n",
    "ntile_10_noDOM['cost_ratio'] = ntile_10_noDOM.apply(lambda row: row.med_sale_price / np.maximum(1.0, row.SE_A14024_001), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_sale_price</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>new_listings</th>\n",
       "      <th>inventory</th>\n",
       "      <th>ppsf</th>\n",
       "      <th>SE_A00001_001</th>\n",
       "      <th>SE_A00002_001</th>\n",
       "      <th>SE_A00002_002</th>\n",
       "      <th>SE_A00002_003</th>\n",
       "      <th>SE_A00003_001</th>\n",
       "      <th>...</th>\n",
       "      <th>SE_A10066_001</th>\n",
       "      <th>SE_A10066_002</th>\n",
       "      <th>SE_A10066_003</th>\n",
       "      <th>SE_A10066_004</th>\n",
       "      <th>SE_A10066_005</th>\n",
       "      <th>SE_A10066_006</th>\n",
       "      <th>SE_A10066_007</th>\n",
       "      <th>SE_A10066_008</th>\n",
       "      <th>Availability</th>\n",
       "      <th>cost_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>445750.000000</td>\n",
       "      <td>844</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>51.916667</td>\n",
       "      <td>304.166667</td>\n",
       "      <td>83782</td>\n",
       "      <td>83782</td>\n",
       "      <td>2857.2200</td>\n",
       "      <td>29.322907</td>\n",
       "      <td>29.460930</td>\n",
       "      <td>...</td>\n",
       "      <td>17109</td>\n",
       "      <td>1459</td>\n",
       "      <td>2822</td>\n",
       "      <td>2349</td>\n",
       "      <td>3354</td>\n",
       "      <td>2606</td>\n",
       "      <td>1978</td>\n",
       "      <td>2541</td>\n",
       "      <td>0.388490</td>\n",
       "      <td>26.553285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>951666.666667</td>\n",
       "      <td>1069</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>90.166667</td>\n",
       "      <td>555.166667</td>\n",
       "      <td>32364</td>\n",
       "      <td>32364</td>\n",
       "      <td>3933.1110</td>\n",
       "      <td>8.228600</td>\n",
       "      <td>8.293452</td>\n",
       "      <td>...</td>\n",
       "      <td>12462</td>\n",
       "      <td>3500</td>\n",
       "      <td>4282</td>\n",
       "      <td>2163</td>\n",
       "      <td>1737</td>\n",
       "      <td>511</td>\n",
       "      <td>137</td>\n",
       "      <td>132</td>\n",
       "      <td>0.349088</td>\n",
       "      <td>18.412821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>277583.333333</td>\n",
       "      <td>2141</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>153.750000</td>\n",
       "      <td>200.916667</td>\n",
       "      <td>61216</td>\n",
       "      <td>61216</td>\n",
       "      <td>2141.8380</td>\n",
       "      <td>28.581056</td>\n",
       "      <td>28.581060</td>\n",
       "      <td>...</td>\n",
       "      <td>17722</td>\n",
       "      <td>3694</td>\n",
       "      <td>4365</td>\n",
       "      <td>3118</td>\n",
       "      <td>2914</td>\n",
       "      <td>1623</td>\n",
       "      <td>1047</td>\n",
       "      <td>961</td>\n",
       "      <td>1.200838</td>\n",
       "      <td>15.885506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>263416.666667</td>\n",
       "      <td>2011</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>189.750000</td>\n",
       "      <td>161.750000</td>\n",
       "      <td>48923</td>\n",
       "      <td>48923</td>\n",
       "      <td>360.4279</td>\n",
       "      <td>135.735894</td>\n",
       "      <td>135.964800</td>\n",
       "      <td>...</td>\n",
       "      <td>15314</td>\n",
       "      <td>3168</td>\n",
       "      <td>4966</td>\n",
       "      <td>2401</td>\n",
       "      <td>2319</td>\n",
       "      <td>1409</td>\n",
       "      <td>645</td>\n",
       "      <td>406</td>\n",
       "      <td>7.230295</td>\n",
       "      <td>11.939836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>460166.666667</td>\n",
       "      <td>1307</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>89.583333</td>\n",
       "      <td>249.833333</td>\n",
       "      <td>29244</td>\n",
       "      <td>29244</td>\n",
       "      <td>749.2422</td>\n",
       "      <td>39.031436</td>\n",
       "      <td>39.542950</td>\n",
       "      <td>...</td>\n",
       "      <td>11851</td>\n",
       "      <td>3736</td>\n",
       "      <td>4731</td>\n",
       "      <td>1468</td>\n",
       "      <td>1278</td>\n",
       "      <td>328</td>\n",
       "      <td>217</td>\n",
       "      <td>93</td>\n",
       "      <td>2.110132</td>\n",
       "      <td>11.983507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    med_sale_price  homes_sold  new_listings   inventory        ppsf  \\\n",
       "2    445750.000000         844        1110.0   51.916667  304.166667   \n",
       "8    951666.666667        1069        1373.0   90.166667  555.166667   \n",
       "11   277583.333333        2141        2572.0  153.750000  200.916667   \n",
       "12   263416.666667        2011        2606.0  189.750000  161.750000   \n",
       "14   460166.666667        1307        1581.0   89.583333  249.833333   \n",
       "\n",
       "    SE_A00001_001  SE_A00002_001  SE_A00002_002  SE_A00002_003  SE_A00003_001  \\\n",
       "2           83782          83782      2857.2200      29.322907      29.460930   \n",
       "8           32364          32364      3933.1110       8.228600       8.293452   \n",
       "11          61216          61216      2141.8380      28.581056      28.581060   \n",
       "12          48923          48923       360.4279     135.735894     135.964800   \n",
       "14          29244          29244       749.2422      39.031436      39.542950   \n",
       "\n",
       "    ...  SE_A10066_001  SE_A10066_002  SE_A10066_003  SE_A10066_004  \\\n",
       "2   ...          17109           1459           2822           2349   \n",
       "8   ...          12462           3500           4282           2163   \n",
       "11  ...          17722           3694           4365           3118   \n",
       "12  ...          15314           3168           4966           2401   \n",
       "14  ...          11851           3736           4731           1468   \n",
       "\n",
       "    SE_A10066_005  SE_A10066_006  SE_A10066_007  SE_A10066_008  Availability  \\\n",
       "2            3354           2606           1978           2541      0.388490   \n",
       "8            1737            511            137            132      0.349088   \n",
       "11           2914           1623           1047            961      1.200838   \n",
       "12           2319           1409            645            406      7.230295   \n",
       "14           1278            328            217             93      2.110132   \n",
       "\n",
       "    cost_ratio  \n",
       "2    26.553285  \n",
       "8    18.412821  \n",
       "11   15.885506  \n",
       "12   11.939836  \n",
       "14   11.983507  \n",
       "\n",
       "[5 rows x 169 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set variables to hold test and training data.\n",
    "\n",
    "# Shuffle data frame.\n",
    "shuffled = ntile_10_noDOM.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Remove blanks and NaNs\n",
    "shuffled.replace('', np.nan)\n",
    "shuffled = shuffled.dropna(axis=0, how='any')\n",
    "\n",
    "# Split into data and labels.\n",
    "labels = shuffled[\"DoM_10_group\"]\n",
    "del shuffled[\"DoM_10_group\"]\n",
    "zip_codes = shuffled[\"zip_code\"]\n",
    "del shuffled[\"zip_code\"]\n",
    "shuffled = shuffled.apply(lambda x: pd.to_numeric(x))\n",
    "\n",
    "# Create 70% split point.\n",
    "split = int(len(shuffled)*0.7//1)\n",
    "\n",
    "# Store in variables.\n",
    "train_data = shuffled[:split]\n",
    "train_labels = labels[:split]\n",
    "test_data = shuffled[split+1:]\n",
    "test_labels = labels[split+1:]\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 8 7 1 7 5 6 7 1 4 6 1 3 8 7 2 4 8 2 4 4 3 8 1 1 2 6 2 2 8 2 1 4 7 4 8 4\n",
      " 8 8 6 7 7 5 4 9 8 8 7 2 2 8 7 1 4 6 1 7 5 2 7 7 1 7 7 8 7 4 7 6 4 5 8 6 3\n",
      " 3 6 1 1 7 7 7 3 1 5 8 1]\n",
      "0.3023255813953488\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(train_data, train_labels)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(test_data)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate number of incorrect values for each model.\n",
    "num_wrong = sum(test_labels != y_pred)\n",
    "accuracy = (len(test_labels) - num_wrong) / len(test_labels)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winbase\\Anaconda3\\envs\\mids\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 7 4 7 5 8 4 2 7 4 4 7 4 5 5 8 4 8 7 3 7 7 5 8 2 3 9 3 1 5 6 1 5 7 8 6 8\n",
      " 7 6 1 5 8 1 1 1 6 3 5 6 1 6 1 1 1 1 5 1 7 1 3 4 5 4 4 8 8 3 7 7 3 2 9 7 6\n",
      " 7 2 6 7 2 1 2 5 7 6 3 5]\n",
      "0.313953488372093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "def CreateBalancedSampleWeights(y_train, largest_class_weight_coef):\n",
    "    classes = np.unique(y_train, axis = 0)\n",
    "    classes.sort()\n",
    "    class_samples = np.bincount(y_train)\n",
    "    total_samples = class_samples.sum()\n",
    "    n_classes = len(class_samples)\n",
    "    weights = total_samples / (n_classes * class_samples * 1.0)\n",
    "    class_weight_dict = {key : value for (key, value) in zip(classes, weights)}\n",
    "    class_weight_dict[classes[1]] = class_weight_dict[classes[1]] * largest_class_weight_coef\n",
    "    sample_weights = [class_weight_dict[y] for y in y_train]\n",
    "    return sample_weights\n",
    "\n",
    "\n",
    "#pass labels as numpy array\n",
    "weight = CreateBalancedSampleWeights(train_labels, 20.0)\n",
    "\n",
    "#And then use it like this\n",
    "xg = XGBClassifier(n_estimators=3000, weights = weight, max_depth=100)\n",
    "\n",
    "xg.fit(train_data, train_labels)\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = xg.predict(test_data)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate number of incorrect values for each model.\n",
    "num_wrong = sum(test_labels != y_pred)\n",
    "accuracy = (len(test_labels) - num_wrong) / len(test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   zip_code  med_sale_price  homes_sold  new_listings  inventory         ppsf  \\\n",
      "0     93652    1.600000e+05           3           1.0        NaN   123.000000   \n",
      "1     95986    2.358333e+05           8           NaN        1.0   148.666667   \n",
      "2     95387    2.100000e+05           2           2.0        NaN   154.000000   \n",
      "3     94074    1.276000e+06           3           2.0        1.0   580.000000   \n",
      "4     94043    1.468333e+06         747         929.0       23.0  1068.500000   \n",
      "\n",
      "   SE_A00001_001  SE_A00002_001  SE_A00002_002  SE_A00002_003  ...  \\\n",
      "0            426            426     206.346600       2.064488  ...   \n",
      "1             53             53       6.455810       8.209660  ...   \n",
      "2            710            710       6.118941     116.033155  ...   \n",
      "3            197            197      10.620940      18.548271  ...   \n",
      "4          31488          31488    2949.142000      10.677002  ...   \n",
      "\n",
      "   SE_A10066_002  SE_A10066_003  SE_A10066_004  SE_A10066_005  SE_A10066_006  \\\n",
      "0              8             22             17             27             14   \n",
      "1             11             19              0              0              0   \n",
      "2              0             48              0             51             19   \n",
      "3             31             20             43              0              0   \n",
      "4           4152           4293           2126           1629            667   \n",
      "\n",
      "   SE_A10066_007  SE_A10066_008  DoM_10_group  Availability  cost_ratio  \n",
      "0              3             12             1      0.004846   12.010209  \n",
      "1              0              0             1           NaN    8.567969  \n",
      "2             49              0             1      0.326854   16.738403  \n",
      "3              0              0             1      0.188307   11.483908  \n",
      "4             81             76             1      0.315007   20.538429  \n",
      "\n",
      "[5 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "thresholds = np.sort(model.feature_importances_)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    if(thresh > 0.001):\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(train_data)\n",
    "        # train model\n",
    "        selection_model = XGBClassifier()\n",
    "        selection_model.fit(select_X_train, train_labels)\n",
    "        # eval model\n",
    "        select_X_test = selection.transform(test_data)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        #predictions = [round(value) for value in y_pred]\n",
    "        accuracy = accuracy_score(test_labels, y_pred)\n",
    "        print(\"Thresh=%.3f, n=%d, Accuracy: %.4f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5648148148148148\n",
      "{'alpha': 0.1, 'hidden_layer_sizes': 11, 'max_iter': 700, 'random_state': 9, 'solver': 'lbfgs'}\n",
      "0.21395348837209302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winbase\\Anaconda3\\envs\\mids\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "parameters = {'solver': ['lbfgs'], 'max_iter': [700, 900,1100,1300,1500,1700,1900 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "\n",
    "train_data_scaled = preprocessing.scale(train_data)\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n",
    "\n",
    "clf.fit(train_data, train_labels)\n",
    "print(clf.score(train_data, train_labels))\n",
    "print(clf.best_params_)\n",
    "\n",
    "y_pred = clf.predict(test_data)\n",
    "\n",
    "# Calculate number of incorrect values for each model.\n",
    "num_wrong = sum(test_labels != y_pred)\n",
    "accuracy = (len(test_labels) - num_wrong) / len(test_labels)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
