{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering and Regressions\n",
    "\n",
    "We have 2 basic data sources:\n",
    "\n",
    "[Merged Sales] - This is sales data by zip code. It came from https://www.redfin.com/news/data-center/ and it's got a lot of stats in there. Most of the data is medians so it doesn't tell us much about the outliers which almost certainly are skewing some of the data pretty heavily. The Price per SQ Foot is one way to see a little bit of how the market is shaped. These are broken out by zip code and month.\n",
    "\n",
    "[2018_demographic data] - This is 2018 demographic info by zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "#### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33120, 2151)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>Geo_SUMLEV</th>\n",
       "      <th>Geo_GEOCOMP</th>\n",
       "      <th>Geo_LOGRECNO</th>\n",
       "      <th>Geo_ZCTA3</th>\n",
       "      <th>Geo_ZCTA5</th>\n",
       "      <th>SE_A00001_001</th>\n",
       "      <th>SE_A00002_001</th>\n",
       "      <th>SE_A00002_002</th>\n",
       "      <th>SE_A00002_003</th>\n",
       "      <th>...</th>\n",
       "      <th>SE_A10065_001</th>\n",
       "      <th>SE_A10065_002</th>\n",
       "      <th>SE_A10066_001</th>\n",
       "      <th>SE_A10066_002</th>\n",
       "      <th>SE_A10066_003</th>\n",
       "      <th>SE_A10066_004</th>\n",
       "      <th>SE_A10066_005</th>\n",
       "      <th>SE_A10066_006</th>\n",
       "      <th>SE_A10066_007</th>\n",
       "      <th>SE_A10066_008</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>7459</td>\n",
       "      <td>6</td>\n",
       "      <td>601</td>\n",
       "      <td>17242</td>\n",
       "      <td>17242</td>\n",
       "      <td>267.9506</td>\n",
       "      <td>64.347690</td>\n",
       "      <td>...</td>\n",
       "      <td>3237</td>\n",
       "      <td>1849</td>\n",
       "      <td>5517</td>\n",
       "      <td>1346</td>\n",
       "      <td>1768</td>\n",
       "      <td>1222</td>\n",
       "      <td>889</td>\n",
       "      <td>214</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>7460</td>\n",
       "      <td>6</td>\n",
       "      <td>602</td>\n",
       "      <td>38442</td>\n",
       "      <td>38442</td>\n",
       "      <td>1255.4210</td>\n",
       "      <td>30.620812</td>\n",
       "      <td>...</td>\n",
       "      <td>5636</td>\n",
       "      <td>2721</td>\n",
       "      <td>12738</td>\n",
       "      <td>3107</td>\n",
       "      <td>4024</td>\n",
       "      <td>2467</td>\n",
       "      <td>2345</td>\n",
       "      <td>588</td>\n",
       "      <td>163</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>7461</td>\n",
       "      <td>6</td>\n",
       "      <td>603</td>\n",
       "      <td>48814</td>\n",
       "      <td>48814</td>\n",
       "      <td>1543.9250</td>\n",
       "      <td>31.616820</td>\n",
       "      <td>...</td>\n",
       "      <td>8627</td>\n",
       "      <td>4772</td>\n",
       "      <td>19233</td>\n",
       "      <td>5121</td>\n",
       "      <td>6256</td>\n",
       "      <td>4058</td>\n",
       "      <td>2523</td>\n",
       "      <td>1085</td>\n",
       "      <td>118</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>7462</td>\n",
       "      <td>6</td>\n",
       "      <td>606</td>\n",
       "      <td>6437</td>\n",
       "      <td>6437</td>\n",
       "      <td>152.1423</td>\n",
       "      <td>42.309073</td>\n",
       "      <td>...</td>\n",
       "      <td>975</td>\n",
       "      <td>588</td>\n",
       "      <td>2014</td>\n",
       "      <td>474</td>\n",
       "      <td>693</td>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "      <td>120</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>7463</td>\n",
       "      <td>6</td>\n",
       "      <td>610</td>\n",
       "      <td>27073</td>\n",
       "      <td>27073</td>\n",
       "      <td>753.8562</td>\n",
       "      <td>35.912685</td>\n",
       "      <td>...</td>\n",
       "      <td>4317</td>\n",
       "      <td>2125</td>\n",
       "      <td>8858</td>\n",
       "      <td>2194</td>\n",
       "      <td>2972</td>\n",
       "      <td>1679</td>\n",
       "      <td>1440</td>\n",
       "      <td>486</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zip  Geo_SUMLEV  Geo_GEOCOMP  Geo_LOGRECNO  Geo_ZCTA3  Geo_ZCTA5  \\\n",
       "0  601         860            0          7459          6        601   \n",
       "1  602         860            0          7460          6        602   \n",
       "2  603         860            0          7461          6        603   \n",
       "3  606         860            0          7462          6        606   \n",
       "4  610         860            0          7463          6        610   \n",
       "\n",
       "   SE_A00001_001  SE_A00002_001  SE_A00002_002  SE_A00002_003  ...  \\\n",
       "0          17242          17242       267.9506      64.347690  ...   \n",
       "1          38442          38442      1255.4210      30.620812  ...   \n",
       "2          48814          48814      1543.9250      31.616820  ...   \n",
       "3           6437           6437       152.1423      42.309073  ...   \n",
       "4          27073          27073       753.8562      35.912685  ...   \n",
       "\n",
       "   SE_A10065_001  SE_A10065_002  SE_A10066_001  SE_A10066_002  SE_A10066_003  \\\n",
       "0           3237           1849           5517           1346           1768   \n",
       "1           5636           2721          12738           3107           4024   \n",
       "2           8627           4772          19233           5121           6256   \n",
       "3            975            588           2014            474            693   \n",
       "4           4317           2125           8858           2194           2972   \n",
       "\n",
       "   SE_A10066_004  SE_A10066_005  SE_A10066_006  SE_A10066_007  SE_A10066_008  \n",
       "0           1222            889            214             46             32  \n",
       "1           2467           2345            588            163             44  \n",
       "2           4058           2523           1085            118             72  \n",
       "3            343            343            120             19             22  \n",
       "4           1679           1440            486             55             32  \n",
       "\n",
       "[5 rows x 2151 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics = pd.read_csv(\"2018_demographic_data_edited.csv\", delimiter=',')\n",
    "\n",
    "print(demographics.shape) # removed some of the blank columns and columns with strings in excel\n",
    "\n",
    "demo = demographics.fillna(demographics.mean())\n",
    "demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>Feb-16</th>\n",
       "      <th>Mar-16</th>\n",
       "      <th>Apr-16</th>\n",
       "      <th>May-16</th>\n",
       "      <th>Jun-16</th>\n",
       "      <th>Jul-16</th>\n",
       "      <th>Aug-16</th>\n",
       "      <th>Sep-16</th>\n",
       "      <th>Oct-16</th>\n",
       "      <th>...</th>\n",
       "      <th>Dec-19</th>\n",
       "      <th>Jan-20</th>\n",
       "      <th>Feb-20</th>\n",
       "      <th>Mar-20</th>\n",
       "      <th>Apr-20</th>\n",
       "      <th>May-20</th>\n",
       "      <th>Jun-20</th>\n",
       "      <th>Jul-20</th>\n",
       "      <th>Aug-20</th>\n",
       "      <th>Sep-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005</td>\n",
       "      <td>15.40%</td>\n",
       "      <td>5.70%</td>\n",
       "      <td>-29.70%</td>\n",
       "      <td>-24.00%</td>\n",
       "      <td>33.70%</td>\n",
       "      <td>8.60%</td>\n",
       "      <td>5.70%</td>\n",
       "      <td>-9.10%</td>\n",
       "      <td>-4.10%</td>\n",
       "      <td>...</td>\n",
       "      <td>7.30%</td>\n",
       "      <td>-4.30%</td>\n",
       "      <td>6.30%</td>\n",
       "      <td>-7.90%</td>\n",
       "      <td>2.20%</td>\n",
       "      <td>-4.40%</td>\n",
       "      <td>12.40%</td>\n",
       "      <td>-1.30%</td>\n",
       "      <td>4.50%</td>\n",
       "      <td>1.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1031</td>\n",
       "      <td>705.00%</td>\n",
       "      <td>612.00%</td>\n",
       "      <td>-24.60%</td>\n",
       "      <td>-24.60%</td>\n",
       "      <td>-83.20%</td>\n",
       "      <td>-13.70%</td>\n",
       "      <td>-3.30%</td>\n",
       "      <td>-2.00%</td>\n",
       "      <td>27.60%</td>\n",
       "      <td>...</td>\n",
       "      <td>43.90%</td>\n",
       "      <td>-13.80%</td>\n",
       "      <td>70.90%</td>\n",
       "      <td>162.00%</td>\n",
       "      <td>126.90%</td>\n",
       "      <td>-1.00%</td>\n",
       "      <td>-37.80%</td>\n",
       "      <td>-48.30%</td>\n",
       "      <td>-51.10%</td>\n",
       "      <td>681.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-23.90%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.70%</td>\n",
       "      <td>150.40%</td>\n",
       "      <td>150.40%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.40%</td>\n",
       "      <td>-14.50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    zip   Feb-16   Mar-16   Apr-16   May-16   Jun-16   Jul-16   Aug-16  \\\n",
       "0   501      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1  1005   15.40%    5.70%  -29.70%  -24.00%   33.70%    8.60%    5.70%   \n",
       "2  1010      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3  1031  705.00%  612.00%  -24.60%  -24.60%  -83.20%  -13.70%   -3.30%   \n",
       "4  1037      NaN      NaN  -23.90%      NaN  102.70%  150.40%  150.40%   \n",
       "\n",
       "   Sep-16  Oct-16  ...  Dec-19   Jan-20  Feb-20   Mar-20   Apr-20  May-20  \\\n",
       "0     NaN     NaN  ...     NaN      NaN     NaN      NaN      NaN     NaN   \n",
       "1  -9.10%  -4.10%  ...   7.30%   -4.30%   6.30%   -7.90%    2.20%  -4.40%   \n",
       "2     NaN     NaN  ...     NaN      NaN     NaN      NaN      NaN     NaN   \n",
       "3  -2.00%  27.60%  ...  43.90%  -13.80%  70.90%  162.00%  126.90%  -1.00%   \n",
       "4     NaN     NaN  ...     NaN      NaN     NaN      NaN      NaN     NaN   \n",
       "\n",
       "    Jun-20   Jul-20   Aug-20   Sep-20  \n",
       "0      NaN      NaN      NaN      NaN  \n",
       "1   12.40%   -1.30%    4.50%    1.30%  \n",
       "2      NaN      NaN      NaN      NaN  \n",
       "3  -37.80%  -48.30%  -51.10%  681.40%  \n",
       "4      NaN      NaN  -24.40%  -14.50%  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv(\"med_sale_price_yoy.csv\", delimiter=',')\n",
    "sales.rename(columns={\"Zip Code\": \"zip\"}, inplace = True)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Algorithm\n",
    "### K Means\n",
    "#### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2151)\n",
      "[0 2 2 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=6, init='k-means++')\n",
    "clstrs = km.fit(demo)\n",
    "print (clstrs.cluster_centers_.shape)\n",
    "print (clstrs.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add cluster labels and sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33120, 2152)\n",
      "(33120, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zip  cluster\n",
       "0  601        0\n",
       "1  602        2\n",
       "2  603        2\n",
       "3  606        0\n",
       "4  610        2"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add the column for clusters\n",
    "demo['cluster'] = clstrs.labels_\n",
    "print(demo.shape)\n",
    "clusters = pd.DataFrame(demo[['zip','cluster']])\n",
    "print(clusters.shape)\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16201, 57)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>Feb-16</th>\n",
       "      <th>Mar-16</th>\n",
       "      <th>Apr-16</th>\n",
       "      <th>May-16</th>\n",
       "      <th>Jun-16</th>\n",
       "      <th>Jul-16</th>\n",
       "      <th>Aug-16</th>\n",
       "      <th>Sep-16</th>\n",
       "      <th>Oct-16</th>\n",
       "      <th>...</th>\n",
       "      <th>Dec-19</th>\n",
       "      <th>Jan-20</th>\n",
       "      <th>Feb-20</th>\n",
       "      <th>Mar-20</th>\n",
       "      <th>Apr-20</th>\n",
       "      <th>May-20</th>\n",
       "      <th>Jun-20</th>\n",
       "      <th>Jul-20</th>\n",
       "      <th>Aug-20</th>\n",
       "      <th>Sep-20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.40%</td>\n",
       "      <td>5.70%</td>\n",
       "      <td>-29.70%</td>\n",
       "      <td>-24.00%</td>\n",
       "      <td>33.70%</td>\n",
       "      <td>8.60%</td>\n",
       "      <td>5.70%</td>\n",
       "      <td>-9.10%</td>\n",
       "      <td>-4.10%</td>\n",
       "      <td>...</td>\n",
       "      <td>7.30%</td>\n",
       "      <td>-4.30%</td>\n",
       "      <td>6.30%</td>\n",
       "      <td>-7.90%</td>\n",
       "      <td>2.20%</td>\n",
       "      <td>-4.40%</td>\n",
       "      <td>12.40%</td>\n",
       "      <td>-1.30%</td>\n",
       "      <td>4.50%</td>\n",
       "      <td>1.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.0</td>\n",
       "      <td>705.00%</td>\n",
       "      <td>612.00%</td>\n",
       "      <td>-24.60%</td>\n",
       "      <td>-24.60%</td>\n",
       "      <td>-83.20%</td>\n",
       "      <td>-13.70%</td>\n",
       "      <td>-3.30%</td>\n",
       "      <td>-2.00%</td>\n",
       "      <td>27.60%</td>\n",
       "      <td>...</td>\n",
       "      <td>43.90%</td>\n",
       "      <td>-13.80%</td>\n",
       "      <td>70.90%</td>\n",
       "      <td>162.00%</td>\n",
       "      <td>126.90%</td>\n",
       "      <td>-1.00%</td>\n",
       "      <td>-37.80%</td>\n",
       "      <td>-48.30%</td>\n",
       "      <td>-51.10%</td>\n",
       "      <td>681.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-23.90%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.70%</td>\n",
       "      <td>150.40%</td>\n",
       "      <td>150.40%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.40%</td>\n",
       "      <td>-14.50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cluster   Feb-16   Mar-16   Apr-16   May-16   Jun-16   Jul-16   Aug-16  \\\n",
       "zip                                                                            \n",
       "501       NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1005      0.0   15.40%    5.70%  -29.70%  -24.00%   33.70%    8.60%    5.70%   \n",
       "1010      0.0      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1031      0.0  705.00%  612.00%  -24.60%  -24.60%  -83.20%  -13.70%   -3.30%   \n",
       "1037      0.0      NaN      NaN  -23.90%      NaN  102.70%  150.40%  150.40%   \n",
       "\n",
       "      Sep-16  Oct-16  ...  Dec-19   Jan-20  Feb-20   Mar-20   Apr-20  May-20  \\\n",
       "zip                   ...                                                      \n",
       "501      NaN     NaN  ...     NaN      NaN     NaN      NaN      NaN     NaN   \n",
       "1005  -9.10%  -4.10%  ...   7.30%   -4.30%   6.30%   -7.90%    2.20%  -4.40%   \n",
       "1010     NaN     NaN  ...     NaN      NaN     NaN      NaN      NaN     NaN   \n",
       "1031  -2.00%  27.60%  ...  43.90%  -13.80%  70.90%  162.00%  126.90%  -1.00%   \n",
       "1037     NaN     NaN  ...     NaN      NaN     NaN      NaN      NaN     NaN   \n",
       "\n",
       "       Jun-20   Jul-20   Aug-20   Sep-20  \n",
       "zip                                       \n",
       "501       NaN      NaN      NaN      NaN  \n",
       "1005   12.40%   -1.30%    4.50%    1.30%  \n",
       "1010      NaN      NaN      NaN      NaN  \n",
       "1031  -37.80%  -48.30%  -51.10%  681.40%  \n",
       "1037      NaN      NaN  -24.40%  -14.50%  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join the sales data (has less zip codes, so right join)\n",
    "data = clusters.set_index('zip').join(sales.set_index('zip'), how ='right')\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0\n",
      "(6225, 57)\n",
      "(348600, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-188-1d705da33ec5>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust0['parsed_date'] = pd.to_datetime(clust0.loc[:,'date'], format='%b-%y')\n",
      "<ipython-input-188-1d705da33ec5>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust0['days_from_start'] = clust0.loc[:,'parsed_date'] - clust0.loc[0, 'parsed_date']\n",
      "<ipython-input-188-1d705da33ec5>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust0['yoy'] = clust0['yoy'].str.replace(r'%', r'')\n",
      "<ipython-input-188-1d705da33ec5>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust0['yoy'] = pd.to_numeric(clust0[\"yoy\"], downcast=\"float\")\n",
      "<ipython-input-188-1d705da33ec5>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust1['parsed_date'] = pd.to_datetime(clust1.loc[:,'date'], format='%b-%y')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243137, 5)\n",
      "          zip    date         yoy parsed_date days_from_start\n",
      "0        1005  Feb-16   15.400000  2016-02-01          0 days\n",
      "1        1031  Feb-16  705.000000  2016-02-01          0 days\n",
      "2        1068  Feb-16  -13.200000  2016-02-01          0 days\n",
      "3        1083  Feb-16  -63.599998  2016-02-01          0 days\n",
      "4        1366  Feb-16   20.100000  2016-02-01          0 days\n",
      "...       ...     ...         ...         ...             ...\n",
      "243122  99137  Sep-20  -11.400000  2020-09-01       1674 days\n",
      "243123  99141  Sep-20   -7.900000  2020-09-01       1674 days\n",
      "243124  99148  Sep-20   72.199997  2020-09-01       1674 days\n",
      "243125  99173  Sep-20   -4.400000  2020-09-01       1674 days\n",
      "243126  99181  Sep-20  -11.300000  2020-09-01       1674 days\n",
      "\n",
      "[243127 rows x 5 columns]\n",
      "\n",
      "Group 1\n",
      "(100900, 5)\n",
      "          zip    date      yoy parsed_date days_from_start\n",
      "0        1453  Feb-16   19.50%  2016-02-01          0 days\n",
      "1        1545  Feb-16  -15.90%  2016-02-01          0 days\n",
      "2        1702  Feb-16    6.70%  2016-02-01          0 days\n",
      "3        1720  Feb-16    2.50%  2016-02-01          0 days\n",
      "4        1742  Feb-16  -12.40%  2016-02-01          0 days\n",
      "...       ...     ...      ...         ...             ...\n",
      "100885  98632  Sep-20   16.80%  2020-09-01       1674 days\n",
      "100886  98661  Sep-20    8.90%  2020-09-01       1674 days\n",
      "100887  98682  Sep-20    6.80%  2020-09-01       1674 days\n",
      "100888  98683  Sep-20    6.70%  2020-09-01       1674 days\n",
      "100889  98685  Sep-20    5.10%  2020-09-01       1674 days\n",
      "\n",
      "[100890 rows x 5 columns]\n",
      "\n",
      "Group 2\n",
      "(182557, 5)\n",
      "          zip    date      yoy parsed_date days_from_start\n",
      "0        1331  Feb-16   23.80%  2016-02-01          0 days\n",
      "1        1430  Feb-16   18.40%  2016-02-01          0 days\n",
      "2        1432  Feb-16   -9.60%  2016-02-01          0 days\n",
      "3        1440  Feb-16    3.30%  2016-02-01          0 days\n",
      "4        1451  Feb-16  -11.50%  2016-02-01          0 days\n",
      "...       ...     ...      ...         ...             ...\n",
      "182542  99021  Sep-20    7.50%  2020-09-01       1674 days\n",
      "182543  99022  Sep-20    7.60%  2020-09-01       1674 days\n",
      "182544  99026  Sep-20    8.60%  2020-09-01       1674 days\n",
      "182545  99027  Sep-20   32.00%  2020-09-01       1674 days\n",
      "182546  99037  Sep-20   -4.90%  2020-09-01       1674 days\n",
      "\n",
      "[182547 rows x 5 columns]\n",
      "\n",
      "Group 3\n",
      "(5089, 5)\n",
      "        zip    date      yoy parsed_date days_from_start\n",
      "0      8540  Feb-16   29.80%  2016-02-01          0 days\n",
      "1     11746  Feb-16    4.10%  2016-02-01          0 days\n",
      "2     20009  Feb-16   17.50%  2016-02-01          0 days\n",
      "3     20016  Feb-16    3.40%  2016-02-01          0 days\n",
      "4     20147  Feb-16    6.60%  2016-02-01          0 days\n",
      "...     ...     ...      ...         ...             ...\n",
      "5074  94025  Sep-20    6.80%  2020-09-01       1674 days\n",
      "5075  94087  Sep-20    7.00%  2020-09-01       1674 days\n",
      "5076  94109  Sep-20    5.40%  2020-09-01       1674 days\n",
      "5077  94110  Sep-20   -6.40%  2020-09-01       1674 days\n",
      "5078  94114  Sep-20  -12.90%  2020-09-01       1674 days\n",
      "\n",
      "[5079 rows x 5 columns]\n",
      "\n",
      "Group 4\n",
      "(38571, 5)\n",
      "         zip    date     yoy parsed_date days_from_start\n",
      "0       1701  Feb-16  11.10%  2016-02-01          0 days\n",
      "1       1760  Feb-16  12.40%  2016-02-01          0 days\n",
      "2       1810  Feb-16   3.10%  2016-02-01          0 days\n",
      "3       1890  Feb-16  11.20%  2016-02-01          0 days\n",
      "4       1915  Feb-16   4.30%  2016-02-01          0 days\n",
      "...      ...     ...     ...         ...             ...\n",
      "38556  98034  Sep-20  16.10%  2020-09-01       1674 days\n",
      "38557  98040  Sep-20   4.80%  2020-09-01       1674 days\n",
      "38558  98042  Sep-20  18.20%  2020-09-01       1674 days\n",
      "38559  98074  Sep-20  10.10%  2020-09-01       1674 days\n",
      "38560  98102  Sep-20  13.80%  2020-09-01       1674 days\n",
      "\n",
      "[38561 rows x 5 columns]\n",
      "\n",
      "Group 5\n",
      "(150189, 5)\n",
      "          zip    date     yoy parsed_date days_from_start\n",
      "0        1420  Feb-16  24.00%  2016-02-01          0 days\n",
      "1        1450  Feb-16  21.30%  2016-02-01          0 days\n",
      "2        1501  Feb-16   0.40%  2016-02-01          0 days\n",
      "3        1507  Feb-16  -0.70%  2016-02-01          0 days\n",
      "4        1520  Feb-16  20.60%  2016-02-01          0 days\n",
      "...       ...     ...     ...         ...             ...\n",
      "150174  98802  Sep-20   3.80%  2020-09-01       1674 days\n",
      "150175  98926  Sep-20   0.60%  2020-09-01       1674 days\n",
      "150176  99019  Sep-20   6.70%  2020-09-01       1674 days\n",
      "150177  99203  Sep-20  26.10%  2020-09-01       1674 days\n",
      "150178  99212  Sep-20  21.30%  2020-09-01       1674 days\n",
      "\n",
      "[150179 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-188-1d705da33ec5>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust1['days_from_start'] = clust1.loc[:,'parsed_date'] - clust1.loc[0, 'parsed_date']\n",
      "<ipython-input-188-1d705da33ec5>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust2['parsed_date'] = pd.to_datetime(clust2.loc[:,'date'], format='%b-%y')\n",
      "<ipython-input-188-1d705da33ec5>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust2['days_from_start'] = clust2.loc[:,'parsed_date'] - clust2.loc[0, 'parsed_date']\n",
      "<ipython-input-188-1d705da33ec5>:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust3['parsed_date'] = pd.to_datetime(clust3['date'], format='%b-%y')\n",
      "<ipython-input-188-1d705da33ec5>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust3['days_from_start'] = clust3.loc[:,'parsed_date'] - clust3.loc[0, 'parsed_date']\n",
      "<ipython-input-188-1d705da33ec5>:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust4['parsed_date'] = pd.to_datetime(clust4['date'], format='%b-%y')\n",
      "<ipython-input-188-1d705da33ec5>:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust4['days_from_start'] = clust4.loc[:,'parsed_date'] - clust4.loc[0, 'parsed_date']\n",
      "<ipython-input-188-1d705da33ec5>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust5['parsed_date'] = pd.to_datetime(clust5['date'], format='%b-%y')\n",
      "<ipython-input-188-1d705da33ec5>:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clust5['days_from_start'] = clust5.loc[:,'parsed_date'] - clust5.loc[0, 'parsed_date']\n"
     ]
    }
   ],
   "source": [
    "print('Group 0')\n",
    "clust0 = data[data['cluster']==0]\n",
    "print(clust0.shape)\n",
    "clust0 = clust0.drop(columns=['cluster'])\n",
    "clust0_melt = pd.melt(clust0.reset_index(), id_vars=['zip'], value_vars=list(clust0.columns), var_name='date', value_name='yoy')\n",
    "print(clust0_melt.shape)\n",
    "clust0 = clust0_melt.dropna()\n",
    "clust0.reset_index(drop=True, inplace=True)\n",
    "clust0['parsed_date'] = pd.to_datetime(clust0.loc[:,'date'], format='%b-%y')\n",
    "clust0['days_from_start'] = clust0.loc[:,'parsed_date'] - clust0.loc[0, 'parsed_date']\n",
    "clust0['yoy'] = clust0['yoy'].str.replace(r'%', r'')\n",
    "clust0['yoy'] = pd.to_numeric(clust0[\"yoy\"], downcast=\"float\")\n",
    "print(clust0.shape)\n",
    "print(clust0.head(-10))\n",
    "\n",
    "print('''\n",
    "Group 1''')\n",
    "clust1 = data[data['cluster']==1]\n",
    "clust1 = clust1.drop(columns=['cluster'])\n",
    "clust1_melt = pd.melt(clust1.reset_index(), id_vars=['zip'], value_vars=list(clust1.columns), var_name='date', value_name='yoy')\n",
    "clust1 = clust1_melt.dropna()\n",
    "clust1.reset_index(drop=True, inplace=True)\n",
    "clust1['parsed_date'] = pd.to_datetime(clust1.loc[:,'date'], format='%b-%y')\n",
    "clust1['days_from_start'] = clust1.loc[:,'parsed_date'] - clust1.loc[0, 'parsed_date']\n",
    "print(clust1.shape)\n",
    "print(clust1.head(-10))\n",
    "\n",
    "print('''\n",
    "Group 2''')\n",
    "clust2 = data[data['cluster']==2]\n",
    "clust2 = clust2.drop(columns=['cluster'])\n",
    "clust2_melt = pd.melt(clust2.reset_index(), id_vars=['zip'], value_vars=list(clust2.columns), var_name='date', value_name='yoy')\n",
    "clust2 = clust2_melt.dropna()\n",
    "clust2.reset_index(drop=True, inplace=True)\n",
    "clust2['parsed_date'] = pd.to_datetime(clust2.loc[:,'date'], format='%b-%y')\n",
    "clust2['days_from_start'] = clust2.loc[:,'parsed_date'] - clust2.loc[0, 'parsed_date']\n",
    "print(clust2.shape)\n",
    "print(clust2.head(-10))\n",
    "\n",
    "print('''\n",
    "Group 3''')\n",
    "clust3 = data[data['cluster']==3]\n",
    "clust3 = clust3.drop(columns=['cluster'])\n",
    "clust3_melt = pd.melt(clust3.reset_index(), id_vars=['zip'], value_vars=list(clust3.columns), var_name='date', value_name='yoy')\n",
    "clust3 = clust3_melt.dropna()\n",
    "clust3.reset_index(drop=True, inplace=True)\n",
    "clust3['parsed_date'] = pd.to_datetime(clust3['date'], format='%b-%y')\n",
    "clust3['days_from_start'] = clust3.loc[:,'parsed_date'] - clust3.loc[0, 'parsed_date']\n",
    "print(clust3.shape)\n",
    "print(clust3.head(-10))\n",
    "\n",
    "print('''\n",
    "Group 4''')\n",
    "clust4 = data[data['cluster']==4]\n",
    "clust4 = clust4.drop(columns=['cluster'])\n",
    "clust4_melt = pd.melt(clust4.reset_index(), id_vars=['zip'], value_vars=list(clust4.columns), var_name='date', value_name='yoy')\n",
    "clust4 = clust4_melt.dropna()\n",
    "clust4.reset_index(drop=True, inplace=True)\n",
    "clust4['parsed_date'] = pd.to_datetime(clust4['date'], format='%b-%y')\n",
    "clust4['days_from_start'] = clust4.loc[:,'parsed_date'] - clust4.loc[0, 'parsed_date']\n",
    "print(clust4.shape)\n",
    "print(clust4.head(-10))\n",
    "\n",
    "print('''\n",
    "Group 5''')\n",
    "clust5 = data[data['cluster']==5]\n",
    "clust5 = clust5.drop(columns=['cluster'])\n",
    "clust5_melt = pd.melt(clust5.reset_index(), id_vars=['zip'], value_vars=list(clust5.columns), var_name='date', value_name='yoy')\n",
    "clust5 = clust5_melt.dropna()\n",
    "clust5.reset_index(drop=True, inplace=True)\n",
    "clust5['parsed_date'] = pd.to_datetime(clust5['date'], format='%b-%y')\n",
    "clust5['days_from_start'] = clust5.loc[:,'parsed_date'] - clust5.loc[0, 'parsed_date']\n",
    "print(clust5.shape)\n",
    "print(clust5.head(-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Linear Regressions for each Group\n",
    "##### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = clust0['days_from_start'].values\n",
    "y = clust0['yoy'].values\n",
    "\n",
    "\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "model = linear_model.LinearRegression().fit(x, y)\n",
    "linear_model.LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "\n",
    "\n",
    "# x = list(x.flatten())\n",
    "# y = list(y)\n",
    "\n",
    "# print(x)\n",
    "# print(y)\n",
    "\n",
    "# plt.scatter(x, y,  color='black')\n",
    "\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
